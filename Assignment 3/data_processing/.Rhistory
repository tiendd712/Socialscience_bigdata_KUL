levels = c(0, 1))
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -employee_id, -promote_general, -promote_level_2, connection_count) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
rm(df)
View(df_level_1)
str(df_level_1)
View(df_level_1)
View(gender_data)
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -promote_general, -promote_level_2, connection_count) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
View(df_level_1)
View(gender_data)
gender_data %>% filter(employee_id == "t_10")
View(connection_data)
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -promote_general, -promote_level_2, connection_count) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1)),
connection_type = factor(connection_type, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
View(connection_data)
str(df_level_1)
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -promote_general, -promote_level_2, -connection_count) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1)),
connection_type = factor(connection_type, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
str(df_level_1)
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -promote_general, -promote_level_2, -connection_count, -employee_id) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1)),
connection_type = factor(connection_type, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
View(df_level_1)
# Split data into train and test sets
set.seed(7)
train_indices <- createDataPartition(y = df_level_1$promote_level_1, p = 0.8, list = FALSE)
data_train_level_1 <- df_level_1[train_indices, ]
data_test_level_1 <- df_level_1[-train_indices, ]
dim(data_train_level_1)
dim(data_train_level_1)
dim(data_test_level_1)
prop.table(table(data_train_level_1$promote_level_1))
prop.table(table(data_test_level_1$promote_level_1))
df_level_1 = exp_data %>%
merge(edu_data, by = "employee_id", all.x = TRUE) %>%
filter(time_work > 0) %>%
merge(lang_data, by = "employee_id", all.x = TRUE) %>%
merge(connection_data, by = "employee_id", all.x = TRUE) %>%
merge(follower_data, by = "employee_id", all.x = TRUE) %>%
merge(skill_data, by = "employee_id", all.x = TRUE) %>%
merge(gender_data, by = "employee_id", all.x = TRUE) %>%
filter(!(promote_level_1 ==  0 & promote_level_2 == 1)) %>%
select(-skills, -skill_trans, -strongest_role, -skill4, -last_edu_year, -promote_general, -promote_level_2, -connection_count, -employee_id) %>%
mutate(gender_predict = ifelse(is.na(gender_predict), "Neutral", gender_predict)) %>%
mutate(promote_level_1 = ifelse(is.na(promote_level_1), 0, promote_level_1)) %>%
mutate(highest_edu = ifelse(is.na(highest_edu), "bachelor", highest_edu)) %>%
replace(is.na(.), 0) %>%
mutate(promote_level_1 = factor(promote_level_1, levels = c(0, 1), labels = c(0, 1)),
gender_predict = factor(gender_predict, levels = c("Man", "Woman", "Neutral"), labels = c(0, 1, 2)),
highest_edu = factor(highest_edu, levels = c("bachelor", "master", "phd"), labels = c(0, 1, 2)),
has_relevant_field = factor(has_relevant_field, levels = c(0, 1), labels = c(0, 1)),
intern = factor(intern, levels = c(0, 1), labels = c(0, 1)),
connection_type = factor(connection_type, levels = c(0, 1), labels = c(0, 1))) %>%
mutate_at(vars(all_of(language_columns)), factor,
levels = c(0, 1))
set.seed(7)
train_indices <- createDataPartition(y = df_level_1$promote_level_1, p = 0.8, list = FALSE)
data_train_level_1 <- df_level_1[train_indices, ]
data_test_level_1 <- df_level_1[-train_indices, ]
dim(data_train_level_1)
dim(data_test_level_1)
# Check probability of each type in train/test set
prop.table(table(data_train_level_1$promote_level_1))
prop.table(table(data_test_level_1$promote_level_1))
model_params <- list(
random_forest = list(
model = "randomForest",
params = list(
ntree = sample(50:100, 1),
mtry = sample(3:50, 1),
maxnodes = Inf,
nodesize = sample(2:20, 1),
importance = TRUE,
do.trace = FALSE,
keep.forest = FALSE,
replace = TRUE
)
),
gradient_boosting = list(
model = "gbm",
params = list(
n.trees = sample(50:100, 1),
shrinkage = runif(1, 0.01, 0.5),
interaction.depth = sample(1:10, 1),
n.minobsinnode = sample(2:20, 1),
bag.fraction = 0.5,
train.fraction = 1.0,
verbose = FALSE
)
),
xgboost = list(
model = "xgboost",
params = list(
nrounds = sample(50:100, 1),
eta = runif(1, 0.01, 0.5),
max_depth = sample(1:10, 1),
min_child_weight = sample(1:10, 1),
gamma = runif(1, 0, 1),
alpha = runif(1, 0, 1),
lambda = runif(1, 0, 1)
)
)
)
params_dict <- list()
data_train_level_1[-promote_level_1]
data_train_level_1
data_train_level_1[,-promote_level_1, drop = T]
data_train_level_1[,"promote_level_1", drop = T
data_train_level_1[,"promote_level_1", drop = T]
data_train_level_1[,"promote_level_1", drop = T]
data_train_level_1 %>% select(-promote_level_1)
model_params <- list(
random_forest = list(
model = "randomForest",
params = list(
ntree = sample(50:100, 1),
mtry = sample(3:50, 1),
maxnodes = Inf,
nodesize = sample(2:20, 1),
importance = TRUE,
do.trace = FALSE,
keep.forest = FALSE,
replace = TRUE
)
),
gradient_boosting = list(
model = "gbm",
params = list(
n.trees = sample(50:100, 1),
shrinkage = runif(1, 0.01, 0.5),
interaction.depth = sample(1:10, 1),
n.minobsinnode = sample(2:20, 1),
bag.fraction = 0.5,
train.fraction = 1.0,
verbose = FALSE
)
),
xgboost = list(
model = "xgboost",
params = list(
nrounds = sample(50:100, 1),
eta = runif(1, 0.01, 0.5),
max_depth = sample(1:10, 1),
min_child_weight = sample(1:10, 1),
gamma = runif(1, 0, 1),
alpha = runif(1, 0, 1),
lambda = runif(1, 0, 1)
)
)
)
params_dict <- list()
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
random_search <- do.call(model, c(list(data = data_train_level_1 %>% select(-promote_level_1),
y = data_train_level_1$promote_level_1), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
random_search <- do.call(model, c(list(data = data_train_level_1 %>% select(-promote_level_1),
y = data_train_level_1$promote_level_1), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
data_train_level_1 %>% select(-promote_level_1) %>% as.matrix()
data_train_level_1 %>% select(-promote_level_1)
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
if (model == "randomForest") {
model_fn <- randomForest
} else if (model == "gbm") {
model_fn <- gbm
} else if (model == "xgboost") {
model_fn <- xgboost
} else {
stop(paste("Model '", model, "' not recognized."))
}
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
random_search <- do.call(model_fn, c(list(data = data_train_level_1 %>% select(-promote_level_1),
y = data_train_level_1$promote_level_1), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
if (model == "randomForest") {
model_fn <- randomForest
} else if (model == "gbm") {
model_fn <- gbm
} else if (model == "xgboost") {
model_fn <- xgboost
} else {
stop(paste("Model '", model, "' not recognized."))
}
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
# Separate the predictor variables (X) and the response variable (y)
X_train <- data_train_level_1 %>% select(-promote_level_1)
y_train <- data_train_level_1$promote_level_1
# Call the model function with the correct arguments
random_search <- do.call(model_fn, c(list(x = X_train, y = y_train), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
View(model_fn)
View(model_fn)
View(model_fn)
View(param_dist)
View(model_params)
model_params <- list(
random_forest = list(
model = "randomForest",
params = list(
ntree = sample(50:100, 1),
mtry = sample(3:50, 1),
nodesize = sample(2:20, 1),
importance = TRUE,
do.trace = FALSE,
keep.forest = FALSE,
replace = TRUE
)
),
gradient_boosting = list(
model = "gbm",
params = list(
n.trees = sample(50:100, 1),
shrinkage = runif(1, 0.01, 0.5),
interaction.depth = sample(1:10, 1),
n.minobsinnode = sample(2:20, 1),
bag.fraction = 0.5,
train.fraction = 1.0,
verbose = FALSE
)
),
xgboost = list(
model = "xgboost",
params = list(
nrounds = sample(50:100, 1),
eta = runif(1, 0.01, 0.5),
max_depth = sample(1:10, 1),
min_child_weight = sample(1:10, 1),
gamma = runif(1, 0, 1),
alpha = runif(1, 0, 1),
lambda = runif(1, 0, 1)
)
)
)
params_dict <- list()
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
if (model == "randomForest") {
model_fn <- randomForest
} else if (model == "gbm") {
model_fn <- gbm
} else if (model == "xgboost") {
model_fn <- xgboost
} else {
stop(paste("Model '", model, "' not recognized."))
}
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
# Separate the predictor variables (X) and the response variable (y)
X_train <- data_train_level_1 %>% select(-promote_level_1)
y_train <- data_train_level_1$promote_level_1
# Call the model function with the correct arguments
random_search <- do.call(model_fn, c(list(x = X_train, y = y_train), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
data_train_level_1$promote_level_1
str(y_test_level_1)
x_train_level_1 <- data_train_level_1 %>% select(-promote_level_1)
y_train_level_1 <- as.factor(data_train_level_1$promote_level_1)
x_test_level_1 <- data_test_level_1 %>% select(-promote_level_1)
y_test_level_1 <- as.factor(data_test_level_1$promote_level_1)
print(levels(y_train_level_1))
print(levels(y_test_level_1))
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
if (model == "randomForest") {
model_fn <- randomForest
} else if (model == "gbm") {
model_fn <- gbm
} else if (model == "xgboost") {
model_fn <- xgboost
} else {
stop(paste("Model '", model, "' not recognized."))
}
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
# Call the model function with the correct arguments
random_search <- do.call(model_fn, c(list(x = x_train_level_1, y = y_train_level_1), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
rf_model_level_1 <- randomForest(x_train_level_1, y_train_level_1, ntree = 100, classwt = c(1, 1))
print(rf_model_level_1)
model_params <- list(
random_forest = list(
model = "randomForest",
params = list(
ntree = sample(50:100, 1),
mtry = sample(3:50, 1),
nodesize = sample(2:20, 1),
classwt = c(1, 1),
importance = TRUE,
do.trace = FALSE,
keep.forest = FALSE,
replace = TRUE
)
),
gradient_boosting = list(
model = "gbm",
params = list(
n.trees = sample(50:100, 1),
shrinkage = runif(1, 0.01, 0.5),
interaction.depth = sample(1:10, 1),
n.minobsinnode = sample(2:20, 1),
bag.fraction = 0.5,
train.fraction = 1.0,
verbose = FALSE
)
),
xgboost = list(
model = "xgboost",
params = list(
nrounds = sample(50:100, 1),
eta = runif(1, 0.01, 0.5),
max_depth = sample(1:10, 1),
min_child_weight = sample(1:10, 1),
gamma = runif(1, 0, 1),
alpha = runif(1, 0, 1),
lambda = runif(1, 0, 1)
)
)
)
params_dict <- list()
for (model_name in names(model_params)) {
cat(paste("Running RandomizedSearchCV for ", model_name, "...\n"))
# Create a RandomizedSearchCV object for the current model
model_info <- model_params[[model_name]]
model <- model_info$model
if (model == "randomForest") {
model_fn <- randomForest
} else if (model == "gbm") {
model_fn <- gbm
} else if (model == "xgboost") {
model_fn <- xgboost
} else {
stop(paste("Model '", model, "' not recognized."))
}
param_dist <- model_info$params
set.seed(7)  # Set random seed for reproducibility
# Call the model function with the correct arguments
random_search <- do.call(model_fn, c(list(x = x_train_level_1, y = y_train_level_1), param_dist))
# Print the best parameters and score
params_dict[[model_name]] <- random_search$bestTune
cat(paste("Best parameters for ", model_name, ": ", as.character(random_search$bestTune), "\n"))
cat(paste("Best score for ", model_name, ": ", max(random_search$results$accuracy), "\n"))
cat("\n")
}
View(param_dist)
View(param_dist)
View(param_dist)
View(params_dict)
View(model_params)
rf_model_level_1 <- randomForest(x_train_level_1, y_train_level_1, ntree = 70, classwt = c(1, 1),
ntry = 16, nodesize = 6, importance = TRUE,
do.trace = FALSE,
keep.forest = FALSE,
replace = TRUE
)
print(rf_model_level_1)
model_fn
names(model_params)
model_params[[model_name]]
