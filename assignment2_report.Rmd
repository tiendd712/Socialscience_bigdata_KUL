---
output: 
  stevetemplates::article:
    fig_caption: true
#bibliography: master.bib
biblio-style: apsr
title: "Assignment 2"
author:
- name: Duc Tien Do, Yixin Mei, Anh Phuong Dinh
  affiliation: KU Leuven
abstract: "Applying machine learning approaches to predict European attitudes towards immigrants using the European Social Survey (ESS) dataset"
keywords: "Say something here"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
endnote: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE,
                      message=FALSE, warning=FALSE,
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      })
```


# Introduction

In the context of global migration, Europe was experiencing a significant resurgence in permanent migration to OECD nations. According to the International Migration Outlook 2014, 2013 preliminary data indicates a 1.1% growth, totaling around 4 million new permanent immigrants. Notably, Germany saw a double-digit increase while other destinations like Italy, Portugal, and Spain observed declines.

This resurgence is primarily propelled by a surge in free-movement migration, rising by 10% in 2012, especially within EU member states. Remarkably, intra-European movements matched legal permanent migration from outside the continent for the first time in 2012, with Germany attracting nearly one-third of these migrants.

Amidst these changing migration patterns, this project analyzes European attitudes towards immigrants using data from the European Social Survey (ESS07), released in October 2015. Through the analysis of this dataset, the study aims to predict European attitudes towards immigrants while discerning the factors most strongly associated with both positive and negative views on immigration.

# Data Preprocessing

In this section, we performed several steps to process our data. Firstly, we selected the `imwbcnt` variable (which indicates whether immigrants make the country a better or worse place to live) as our target variable. Based on our knowledge and experience, we compiled a comprehensive list of independent variables that would be relevant and saved it in the `var_selection.csv` file. Secondly, we treated ordinal variables in the same manner as continuous variables and converted nominal variables into factor data types. Lastly, after analyzing the data, we removed nominal variables with many levels (`cntry`) and variables with a high percentage of missing values (`pdjobev` and `marsts`).

```{r import_lib}
library(tidyverse)
library(readxl)
library(caret)
library(randomForest)
library(kernelshap)
library(shapviz)
library(pROC)
library(dplyr)
library(readxl)
library(ggplot2)
library(gridExtra)
library(RColorBrewer)
library(gplots)
library(sf)
library(mapproj)
library(scales)
```


```{r import_data}
# Import data
ess_data = read_csv("https://raw.githubusercontent.com/tiendd712/Socialscience_bigdata_KUL/master/Assignment%202/ESS-Data-Wizard-subset-2023-08-03.csv")
var_pick = read.csv("https://raw.githubusercontent.com/tiendd712/Socialscience_bigdata_KUL/master/Assignment%202/var_selection.csv",sep=";")
```


```{r}
# Remove columns are not chosen 

ess_data = ess_data[, str_trim(var_pick$var)]

var_pick$var = str_trim(var_pick$var)

var_pick$missing_value = str_trim(var_pick$missing_value)

# Assign NA value for columns

for (stt in c(2:ncol(ess_data))){
  
  command_text = str_c("ess_data = ess_data %>% mutate(", 
                       var_pick[stt, "var", drop = T],
                       "= case_when(",
                       var_pick[stt, "var", drop = T],
                       " %in% ",
                       var_pick[stt, "missing_value", drop = T],
                       " ~ NA, TRUE ~ ", var_pick[stt, "var", drop = T],
                       "))")
  
  eval(parse(text = command_text))
}


# Check NA value 

check_na_ratio = data.frame()
for (i in c(1:ncol(ess_data))){
  check_na_ratio = 
    rbind(check_na_ratio,
          data.frame(col_name = names(ess_data)[i],
              na_ratio = sum(is.na(ess_data[,i, drop = T]))*100/nrow(ess_data)))
}



# Remove pdjobev, marsts variables, which have more than 30% NA rows
ess_data = ess_data %>% select(-pdjobev, -marsts)


# Drop NA value in target variable

ess_data  = ess_data %>% filter(!is.na(imwbcnt))

for (col in var_pick %>% filter(data_type == "nominal") %>% .$var){
  if(col %in% colnames(ess_data)) {
    
    ess_data[, col] = as.factor(ess_data[, col, drop = T])
  }
}

# Calculate NA percentage
na_threshold <- 0.3  
na_percentages <- colMeans(is.na(ess_data))

# Remove columns with NA percentage higher than threshold
cleaned_data <- ess_data[, na_percentages <= na_threshold]

# Remove NA values
cleaned_data <- cleaned_data %>% na.omit()
colnames(cleaned_data)
```


# Exploratory Data Analysis & Visualization

## Define the mapping of countries to regions

First, we filter the world map to keep only European countries. 

```{r}
# Load EU map
world <- map_data("world")
unique(world$region)
eu_map <- subset(world, region %in% c("Austria", "Belgium", "Switzerland", "Czech Republic",
                                      "Germany", "Denmark", "Estonia", "Spain",
                                      "Finland", "France", "UK", "Hungary",
                                      "Lithuania", "Netherlands", "Norway", "Poland",
                                      "Portugal", "Sweden", "Slovenia", "Ireland", "Italy",
                                      "Romania", "Greece", "Belarus", "Serbia", "Croatia", "Moldova",
                                      "Bosnia and Herzegovina", "Albania", "North Macedonia", "Latvia",
                                      "Luxembourg", "Montenegro", "Malta", "Iceland", "Andorra", "
                                      Liechtenstein", "Monaco", "Vatican", "Belarus", "Slovakia"))
eu_map <- eu_map %>% filter(lat < 75)
eu_map <- rename(eu_map, cntryname = region)
```

Next, we map each country code in the `cntry` column to its corresponding region and full country name. Subsequently, we would factorize the newly created `region` and `cntryname` column.

```{r}
# Remove some countries
cleaned_data <- cleaned_data %>% filter(cntry != "IL" & cntry != "LT")

# Define the mapping of countries to regions and country names
country_to_region <- c(
  "AT" = "Western EU", "BE" = "Western EU", "CH" = "Western EU", "CZ" = "Eastern EU", 
  "DE" = "Western EU", "DK" = "Northern EU", "EE" = "Eastern EU", "ES" = "Southern EU", 
  "FI" = "Northern EU", "FR" = "Western EU", "GB" = "Western EU", "HU" = "Eastern EU", 
  "LT" = "Eastern EU", "NL" = "Western EU", "NO" = "Northern EU", "PL" = "Eastern EU", 
  "PT" = "Southern EU", "SE" = "Northern EU", "SI" = "Eastern EU", "IE" = "Western EU"
)

country_code_to_name <- c(
  "AT" = "Austria", "BE" = "Belgium", "CH" = "Switzerland", "CZ" = "Czech Republic",
  "DE" = "Germany", "DK" = "Denmark", "EE" = "Estonia", "ES" = "Spain",
  "FI" = "Finland", "FR" = "France", "GB" = "UK", "HU" = "Hungary",
  "LT" = "Lithuania", "NL" = "Netherlands", "NO" = "Norway", "PL" = "Poland",
  "PT" = "Portugal", "SE" = "Sweden", "SI" = "Slovenia", "IE" = "Ireland"
)

# Create the new categorical columns based on the mapping
cleaned_data$region <- factor(country_to_region[cleaned_data$cntry])
cleaned_data$cntryname <- factor(country_code_to_name[cleaned_data$cntry])
```

Then, specific variables are transformed into categorical or numeric formats. 
```{r}
# Convert variables to categorical
columns_to_cate <- c("crmvct", "rlgblg", "brncntr", "blgetmg", "smegbli",
                        "smegbhw", "smctmbe", "gndr", "chldhm", "eisced")

cleaned_data[columns_to_cate] <- lapply(cleaned_data[columns_to_cate], as.factor)

# Convert variables to numeric
columns_to_nume <- c("tvpol", "ppltrst", "polintr", "lrscale", "stflife", "stfeco",
                        "freehms", "imwbcnt", "happy", "aesfdrk", "rlgdgr", "acetalv",
                        "noimbro", "qfimedu", "qfimlng", "qfimwsk", "qfimcmt", "imtcjob",
                        "imbleco", "imwbcrm", "dfegcf", "dfeghbg", "fclcntr", "agea",
                        "eduyrs", "ipeqopt", "impsafe")

cleaned_data[columns_to_nume] <- lapply(cleaned_data[columns_to_nume], as.numeric)

# Data Summary
# summary(cleaned_data)
```

## Perception on immigrants (`imwbcnt`) by country and region

```{r}
# Create a custom color palette
color_palette <- brewer.pal(12, "Paired")

# Bar plot
ggplot(cleaned_data, aes(x = factor(imwbcnt), fill = region)) +
  geom_bar(mapping = aes(y = ..prop.., group = region), stat = "count") +
  labs(title = "Do immigrants make a country worse or better place to live?", 
  subtitle = "0 - Worst place to live, 10 - Better place to live", x = "Vote", y="Proportion") +
  theme_minimal() +
  scale_fill_manual(values = color_palette) +
  scale_x_discrete(breaks = 0:10, limits = 0:10) +
  theme(legend.position = "right")

# Box plot
ggplot(cleaned_data, aes(x = region, y = imwbcnt, fill = region)) +
  geom_boxplot() +
  labs(title = "Do immigrants make a country worse or better place to live?", 
       subtitle = "0 - Worst place to live, 10 - Better place to live", x = "Region", y = "Vote") +
  theme_minimal() +
  scale_fill_discrete(name = "Region")

ggplot(cleaned_data, aes(x = imwbcnt, y = cntryname, fill= region)) +
  geom_boxplot() +
  labs(title = "Do immigrants make a country worse or better place to live?", 
       subtitle = "0 - Worst place to live, 10 - Better place to live", x = "Vote", y = "Country") +
  theme_minimal() +
  scale_fill_discrete(name = "Region") 
```

The data illustrates a prevalent trend where the majority of votes concerning the impact of immigrants on a country lean towards a neutral to slightly positive stance, with a median vote of 6. Region-wise analysis reveals that Northern Europe tends to hold the most favorable attitude towards immigrants, as indicated by a median vote approaching 6. In contrast, Eastern Europe presents a more varied spectrum of opinions, with inclinations toward negativity.

Indeed, throughout Northern Europe, countries consistently hold a neutral to positive stance on the subject Conversely, within Eastern Europe, Hungary and the Czech Republic stand out for their notably negative viewpoints. Among Western European nations, Austria's outlook appears most pessimistic, spanning from negative to neutral sentiments.

## Percentage of population that are born outside the country

```{r}
noimbro_data <- cleaned_data %>%
  group_by(cntryname) %>%
  summarise(noimbro = mean(noimbro, na.rm = TRUE)) %>% 
  right_join(eu_map, by='cntryname')

ggplot() +
  geom_polygon(data = noimbro_data, aes(fill = noimbro, x = long, y = lat, group = group), colour = "white") +
  scale_fill_gradient(high = "#132B43",
                      low = "#56B1F7",
                      space = "Lab",
                      na.value = "grey50",
                      guide = "colourbar",
                      aesthetics = "fill", name="Percent") +
  labs(title ="On average, out of every 100 people in the country, how many are born outside the country?") +
  theme_void() +
  coord_map()
```
It is evident that Belgium, Switzerland, and the United Kingdom exhibit the highest proportion of individuals born outside their respective countries, approximately accounting for 30% of their populations. In contrast, countries such as Finland, Poland, the Czech Republic, and Hungary maintain some of the lowest percentages, hovering around 10% of their populations.

## Correlation matrix and heatmap

```{r}
cor_matrix <- cor(cleaned_data[, columns_to_nume], use = "pairwise.complete.obs")

heatmap.2(cor_matrix, 
          col = colorRampPalette(c("blue", "white", "red"))(100),
          trace = "none", # Remove color key
          key = TRUE, keysize = 1, key.title = NA,
          main = "Correlation Heatmap of Numeric Columns",
          xlab = "Numeric Columns",
          ylab = "Numeric Columns",
          cexRow = 0.6, cexCol = 0.6,
          symm = TRUE, # Show symmetric plot
          density.info = "none") # Remove density plot
```
As anticipated, variables pertaining to attitudes toward immigrants display strong intercorrelations. These variables also exhibit a positive correlation with factors linked to personal well-being and outlook, such as happiness (`happy`), life satisfaction (`stflife`), contentment with the present state of the economy (`stfeco`), and levels of trust in others (`ppltrst`).

Variables linked to attitudes toward immigrants exhibit a strong negative correlation with variables tied to perceptions of immigrant qualifications. This implies that individuals with higher expectations for immigrant qualifications, including proficiency in the official language, educational achievements, and skill levels, may tend to hold more pessimistic viewpoints regarding the impact of immigrants on a country.

# Model development 
## Target variable

Initially, we attempted to predict the raw value of the `imwbcnt` variable, which ranges from 0 to 10. However, the prediction accuracy of all models was poor. We realized that the value of imwbcnt is subjective, causing the models to struggle with distinguishing between adjacent values (e.g., 5 vs. 6 or 7 vs. 8). Additionally, many respondents gave neutral opinions (values from 4 to 6) about immigrants, which were not of interest to us. As a result, we decided to remove observations with neutral opinions and recategorize the `imwbcnt` variable into two levels: respondents with values from 0 to 4 who believe that immigrants make the country worse, and respondents with values from 7 to 10 who believe the opposite. Our objective is to use independent variables to predict whether respondents have a negative or positive attitude towards immigrants. We also aim to investigate the characteristics of respondents with different opinions about immigrants. This approach could provide valuable insights into the factors that associate with people’s attitudes towards immigration.

```{r target_var}
cleaned_data = cleaned_data %>% select(-cntry)
cleaned_data = cleaned_data %>% filter(!(imwbcnt %in% c(4, 5, 6)))


cleaned_data = cleaned_data %>% 
  mutate(imwbcnt = case_when(between(imwbcnt, 0, 3) ~ 0,
                                   T ~ 1))
```

## Independent variables

In this section, we will use Random Forest algorithm to select the top 15 most important features for predicting respondents’ attitudes towards immigration. We have chosen 39 independent variables based on our intuition and experience. Since tree-based algorithms require numerical inputs, we first need to convert nominal variables into one-hot encoding variables. We then split the data into training and testing datasets with an 80:20 ratio. Next, we built a simple random forest model to select the top 15 most important features as inputs for our final models.

```{r one_hot}

## one hot encoding nominal variable

dummy = dummyVars("~ .",data = ess_data )


ess_data_e = data.frame(predict(dummy, newdata=ess_data))
```

```{r rf_pick_var}

set.seed(7)
train_indices <- createDataPartition(y = ess_data_e$imwbcnt, 
                                     p = 0.8, list = FALSE)
data_train <- ess_data_e[train_indices, ]
data_test <- ess_data_e[-train_indices, ]


## drop na for every column

data_train_drop_all = data_train %>% drop_na()


model_test <- randomForest(as.factor(imwbcnt) ~ ., data = data_train_drop_all)

importance_df = data.frame(
  feature = rownames(importance(model_test)),
  importance = importance(model_test)
)

names(importance_df) = c("feature", 'importance')


importance_feature = importance_df %>% 
  arrange(desc(importance)) %>% 
  head(15) %>% .$feature 


ggplot(data = importance_df %>% arrange(desc(importance)) %>% head(15), 
       aes(x = reorder(feature, importance), y = importance)) +
  geom_bar(stat = "identity") +
  coord_flip() + 
  labs(x = "Feature", y = "Importance", title = "Variable importance") 
  

```

## Random forest 

Initially, we used `random forest` algorithms. We fitted the model by using the training data and cross validation techniques with 5 folds to predict our target variable.

```{r rf}

data_train = data_train[c(importance_feature, "imwbcnt")] %>% drop_na()

data_test= data_test[c(importance_feature, "imwbcnt")] %>% drop_na()


x_train = data_train %>% select(-imwbcnt)
y_train = data_train$imwbcnt

x_test = data_test %>% select(-imwbcnt)
y_test = data_test$imwbcnt

train_control = trainControl(method='cv', number = 5)

## Loading the model or training the model if it is not exists

if(!file.exists(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                "Assignment 2/rf_model.rds", sep = ""))){
  
  rf_model = train(x = x_train,y = as.factor(y_train), method = 'rf', 
                 trControl = train_control)
} else {
  rf_model = readRDS(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                     "Assignment 2/rf_model.rds", sep = ""))

}

```

```{r rf_predict, message=FALSE}

rf_pred = predict(rf_model, newdata = x_test)

rf_performance = confusionMatrix(rf_pred, as.factor(y_test), 
                                 mode = "everything",positive = '1')

rf_auc = roc(y_test, predict(rf_model, newdata = x_test, type = "prob")[[2]])$auc

print(rf_performance)

```

## Gradient boosting

```{r gb}

## Loading the model or training the model if it is not exists

if(!file.exists(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                "Assignment 2/gb_model.rds", sep = ""))){
  
  gb_model = train(x = x_train,y = as.factor(y_train), method = 'gbm', 
                 trControl = train_control)
} else {
  gb_model = readRDS(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                     "Assignment 2/gb_model.rds", sep = ""))

}

```

```{r gb_predict}

gb_pred = predict(gb_model, newdata = x_test)

gb_performance = confusionMatrix(gb_pred, as.factor(y_test),
                                 mode = "everything",positive = '1')

gb_auc = roc(y_test, predict(gb_model, newdata = x_test, type = "prob")[[2]])$auc

print(gb_performance)

```

## XGboost

```{r xg}

## Loading the model or training the model if it is not exists

if(!file.exists(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                "Assignment 2/xg_model.rds", sep = ""))){
  
  xg_model = train(x = x_train,y = as.factor(y_train), method = 'xgbTree', 
                 trControl = train_control)
} else {
  xg_model = readRDS(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                     "Assignment 2/xg_model.rds", sep = ""))

}

```

```{r xg_predict}

xg_pred = predict(xg_model, newdata = x_test)

xg_performance = confusionMatrix(xg_pred, as.factor(y_test), 
                                 mode = "everything",positive = '1')

xg_auc = roc(y_test, predict(xg_model, newdata = x_test, type = "prob")[[2]])$auc

print(xg_performance)

```

## Logistics regression

```{r logis}

## Loading the model or training the model if it is not exists

if(!file.exists(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                "Assignment 2/xg_model.rds", sep = ""))){
  
  lr_model = train(x = x_train,y = as.factor(y_train), 
                   method = 'glm', family='binomial', 
                   trControl = train_control)
} else {
  lr_model = readRDS(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                     "Assignment 2/lr_model.rds", sep = ""))

}

```

```{r logis_predict}

lr_pred = predict(lr_model, newdata = x_test)

lr_performance = confusionMatrix(lr_pred, as.factor(y_test), 
                                 mode = "everything",positive = '1')

lr_auc = roc(y_test, predict(lr_model, newdata = x_test, type = "prob")[[2]])$auc

print(lr_performance)

```

# Model performance

The performance of each model reveals that with our chosen independent variables, we can attain remarkably accurate predictions regarding respondents' sentiments toward immigration—whether positive or negative. This accuracy holds true even when employing simple models like Logistic Regression. Moreover, tree-based algorithms exhibit slightly better performance compared to Logistic Regression.

```{r model_performance}

model_performance = 
  data.frame(Model_name = c("Random Forest", "Gradient Boosting",
                            "XGboost", "Logistics"),
             AUC = c(rf_auc, gb_auc, xg_auc, lr_auc),
             Accuracy = c(rf_performance$overall[1],
                          gb_performance$overall[1],
                          xg_performance$overall[1],
                          lr_performance$overall[1]))

model_performance
```

# Inference

In this section, we would use Logistics regression and Shap plot generated from Random forest model to investigate the association of independent variables with attitude of respondents towards to immigrants. As we can see from the Shap plot, the variables `imwbcrm`, `imtcjob` and `imbleco` are the most important variables to predict our target variable. To be more specific, respondents who think that immigrants make country's crime  problems worse, diminish job opportunities or place a strain on resources through taxes and services, also tend to perceive their country as a less desirable place to live due to immigrants. The Logistics regression show the same result. Furthermore, individuals who exhibit higher levels of interpersonal trust and maintain positive interactions and relationships with individuals from diverse racial or ethnic backgrounds tend to display greater levels of tolerance toward immigrants (`dfeghbg` and `ppltrst` variable).


```{r logis_infer}

summary(lr_model)

```

```{r rf_infer}

## SHAP PLOT

if(!file.exists(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
                "Assignment 2/sv.rds", sep = ""))){
  
  ## Calculate shap values 
  s = kernelshap(rf_model, x_train, x_train[1:10,])
  
  ## Turn them into a shapviz object
  sv <- shapviz(s)

} else {
  sv = readRDS(paste("C:/Users/doduc/Github/Socialscience_bigdata_KUL/",
               "Assignment 2/sv.rds", sep = ""))

}

sv_importance(sv, kind = "beeswarm")
```



